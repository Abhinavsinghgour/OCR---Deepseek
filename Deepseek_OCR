{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOYHsFLfpgO/u5uTPeHGuQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhinavsinghgour/OCR---Deepseek/blob/main/Deepseek_OCR\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Deepseek COR***"
      ],
      "metadata": {
        "id": "PASCSCna-uic"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73c20009",
        "outputId": "76c9d991-6936-47e7-e14a-f14ac848c750"
      },
      "source": [
        "import os\n",
        "import replicate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.language_models.llms import LLM\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from typing import List, Optional, Any\n",
        "import fitz\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9412ba31",
        "outputId": "ab2cbcd2-d95d-4a07-9984-297faba336b5"
      },
      "source": [
        "!pip install replicate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: replicate in /usr/local/lib/python3.12/dist-packages (1.0.7)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from replicate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from replicate) (25.0)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.12/dist-packages (from replicate) (2.12.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from replicate) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (0.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "485025e8"
      },
      "source": [
        "First, let's create a `requirements.txt` file with all the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdc6699e",
        "outputId": "7444bb3e-68cd-4349-a865-bb7c1f3f84a4"
      },
      "source": [
        "%%writefile requirements.txt\n",
        "replicate\n",
        "langchain-openai\n",
        "langchain-core\n",
        "langchain-chroma\n",
        "langchain-text-splitters\n",
        "pymupdf\n",
        "python-dotenv\n",
        "langchain-google-genai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46a48d5a"
      },
      "source": [
        "Now, let's install the libraries listed in `requirements.txt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "26610627",
        "outputId": "9df2367d-d176-44a4-c8f9-94a48ccff6fc"
      },
      "source": [
        "!pip install -r requirements.txt --force-reinstall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting replicate (from -r requirements.txt (line 1))\n",
            "  Using cached replicate-1.0.7-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting langchain-openai (from -r requirements.txt (line 2))\n",
            "  Using cached langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-core (from -r requirements.txt (line 3))\n",
            "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langchain-chroma (from -r requirements.txt (line 4))\n",
            "  Using cached langchain_chroma-1.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langchain-text-splitters (from -r requirements.txt (line 5))\n",
            "  Using cached langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pymupdf (from -r requirements.txt (line 6))\n",
            "  Using cached pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting python-dotenv (from -r requirements.txt (line 7))\n",
            "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-google-genai (from -r requirements.txt (line 8))\n",
            "  Using cached langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate->-r requirements.txt (line 1))\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting packaging (from replicate->-r requirements.txt (line 1))\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pydantic>1.10.7 (from replicate->-r requirements.txt (line 1))\n",
            "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions>=4.5.0 (from replicate->-r requirements.txt (line 1))\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting openai<3.0.0,>=1.109.1 (from langchain-openai->-r requirements.txt (line 2))\n",
            "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai->-r requirements.txt (line 2))\n",
            "  Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core->-r requirements.txt (line 3))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core->-r requirements.txt (line 3))\n",
            "  Downloading langsmith-0.4.49-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core->-r requirements.txt (line 3))\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core->-r requirements.txt (line 3))\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting chromadb<2.0.0,>=1.0.20 (from langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting numpy>=1.26.0 (from langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting build>=1.0.3 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pybase64>=1.4.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers>=0.13.2 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
            "Collecting tqdm>=4.65.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting overrides>=7.3.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting importlib-resources (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich>=10.11.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting jsonschema>=4.19.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Downloading google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting anyio (from httpx<1,>=0.21.0->replicate->-r requirements.txt (line 1))\n",
            "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting certifi (from httpx<1,>=0.21.0->replicate->-r requirements.txt (line 1))\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate->-r requirements.txt (line 1))\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting idna (from httpx<1,>=0.21.0->replicate->-r requirements.txt (line 1))\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.21.0->replicate->-r requirements.txt (line 1))\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core->-r requirements.txt (line 3))\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 3))\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 3))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 3))\n",
            "  Downloading zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai<3.0.0,>=1.109.1->langchain-openai->-r requirements.txt (line 2))\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.10.0 (from openai<3.0.0,>=1.109.1->langchain-openai->-r requirements.txt (line 2))\n",
            "  Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai<3.0.0,>=1.109.1->langchain-openai->-r requirements.txt (line 2))\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>1.10.7->replicate->-r requirements.txt (line 1))\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic>1.10.7->replicate->-r requirements.txt (line 1))\n",
            "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic>1.10.7->replicate->-r requirements.txt (line 1))\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai->-r requirements.txt (line 2))\n",
            "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyproject_hooks (from build>=1.0.3->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting cachetools<7.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading rpds_py-0.29.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting six>=1.9.0 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting python-dateutil>=2.5.3 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting sympy (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 3))\n",
            "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting huggingface-hub<2.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading huggingface_hub-1.1.5-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting filelock (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting typer-slim (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->-r requirements.txt (line 8))\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma->-r requirements.txt (line 4))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Using cached replicate-1.0.7-py3-none-any.whl (48 kB)\n",
            "Using cached langchain_openai-1.1.0-py3-none-any.whl (84 kB)\n",
            "Downloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached langchain_chroma-1.0.0-py3-none-any.whl (12 kB)\n",
            "Using cached langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Using cached pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Using cached langchain_google_genai-3.2.0-py3-none-any.whl (57 kB)\n",
            "Using cached chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
            "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.4.49-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.9/410.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.6/463.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "Using cached build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.7/173.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.1/223.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "Using cached onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "Using cached opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "Downloading orjson-3.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.3/136.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Using cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.3.1-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.5/297.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_status-1.76.0-py3-none-any.whl (14 kB)\n",
            "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Using cached httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "Downloading huggingface_hub-1.1.5-py3-none-any.whl (516 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.0/516.0 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.29.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.3/395.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Using cached uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "Using cached watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.5/182.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
            "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.0/201.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypika, mpmath, flatbuffers, filetype, durationpy, zstandard, zipp, websockets, websocket-client, uvloop, urllib3, typing_extensions, tqdm, tenacity, sympy, sniffio, six, shellingham, rpds-py, regex, pyyaml, python-dotenv, pyproject_hooks, pymupdf, pygments, pybase64, pyasn1, protobuf, packaging, overrides, orjson, oauthlib, numpy, mmh3, mdurl, jsonpointer, jiter, importlib-resources, idna, humanfriendly, httptools, hf-xet, h11, fsspec, filelock, distro, click, charset_normalizer, certifi, cachetools, bcrypt, backoff, attrs, annotated-types, uvicorn, typing-inspection, typer-slim, rsa, requests, referencing, python-dateutil, pydantic-core, pyasn1-modules, proto-plus, opentelemetry-proto, markdown-it-py, jsonpatch, importlib-metadata, httpcore, grpcio, googleapis-common-protos, coloredlogs, build, anyio, watchfiles, tiktoken, rich, requests-toolbelt, requests-oauthlib, pydantic, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, jsonschema-specifications, httpx, grpcio-status, google-auth, typer, replicate, opentelemetry-semantic-conventions, openai, langsmith, kubernetes, jsonschema, huggingface-hub, google-api-core, tokenizers, opentelemetry-sdk, langchain-core, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, google-ai-generativelanguage, langchain-google-genai, chromadb, langchain-chroma\n",
            "  Attempting uninstall: pypika\n",
            "    Found existing installation: PyPika 0.48.9\n",
            "    Uninstalling PyPika-0.48.9:\n",
            "      Successfully uninstalled PyPika-0.48.9\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.9.23\n",
            "    Uninstalling flatbuffers-25.9.23:\n",
            "      Successfully uninstalled flatbuffers-25.9.23\n",
            "  Attempting uninstall: filetype\n",
            "    Found existing installation: filetype 1.2.0\n",
            "    Uninstalling filetype-1.2.0:\n",
            "      Successfully uninstalled filetype-1.2.0\n",
            "  Attempting uninstall: durationpy\n",
            "    Found existing installation: durationpy 0.10\n",
            "    Uninstalling durationpy-0.10:\n",
            "      Successfully uninstalled durationpy-0.10\n",
            "  Attempting uninstall: zstandard\n",
            "    Found existing installation: zstandard 0.25.0\n",
            "    Uninstalling zstandard-0.25.0:\n",
            "      Successfully uninstalled zstandard-0.25.0\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.23.0\n",
            "    Uninstalling zipp-3.23.0:\n",
            "      Successfully uninstalled zipp-3.23.0\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: websocket-client\n",
            "    Found existing installation: websocket-client 1.9.0\n",
            "    Uninstalling websocket-client-1.9.0:\n",
            "      Successfully uninstalled websocket-client-1.9.0\n",
            "  Attempting uninstall: uvloop\n",
            "    Found existing installation: uvloop 0.22.1\n",
            "    Uninstalling uvloop-0.22.1:\n",
            "      Successfully uninstalled uvloop-0.22.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: shellingham\n",
            "    Found existing installation: shellingham 1.5.4\n",
            "    Uninstalling shellingham-1.5.4:\n",
            "      Successfully uninstalled shellingham-1.5.4\n",
            "  Attempting uninstall: rpds-py\n",
            "    Found existing installation: rpds-py 0.29.0\n",
            "    Uninstalling rpds-py-0.29.0:\n",
            "      Successfully uninstalled rpds-py-0.29.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.11.3\n",
            "    Uninstalling regex-2025.11.3:\n",
            "      Successfully uninstalled regex-2025.11.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.3\n",
            "    Uninstalling PyYAML-6.0.3:\n",
            "      Successfully uninstalled PyYAML-6.0.3\n",
            "  Attempting uninstall: python-dotenv\n",
            "    Found existing installation: python-dotenv 1.2.1\n",
            "    Uninstalling python-dotenv-1.2.1:\n",
            "      Successfully uninstalled python-dotenv-1.2.1\n",
            "  Attempting uninstall: pyproject_hooks\n",
            "    Found existing installation: pyproject_hooks 1.2.0\n",
            "    Uninstalling pyproject_hooks-1.2.0:\n",
            "      Successfully uninstalled pyproject_hooks-1.2.0\n",
            "  Attempting uninstall: pymupdf\n",
            "    Found existing installation: PyMuPDF 1.26.6\n",
            "    Uninstalling PyMuPDF-1.26.6:\n",
            "      Successfully uninstalled PyMuPDF-1.26.6\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.2\n",
            "    Uninstalling Pygments-2.19.2:\n",
            "      Successfully uninstalled Pygments-2.19.2\n",
            "  Attempting uninstall: pybase64\n",
            "    Found existing installation: pybase64 1.4.2\n",
            "    Uninstalling pybase64-1.4.2:\n",
            "      Successfully uninstalled pybase64-1.4.2\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.1\n",
            "    Uninstalling pyasn1-0.6.1:\n",
            "      Successfully uninstalled pyasn1-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: overrides\n",
            "    Found existing installation: overrides 7.7.0\n",
            "    Uninstalling overrides-7.7.0:\n",
            "      Successfully uninstalled overrides-7.7.0\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.11.4\n",
            "    Uninstalling orjson-3.11.4:\n",
            "      Successfully uninstalled orjson-3.11.4\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.3.1\n",
            "    Uninstalling oauthlib-3.3.1:\n",
            "      Successfully uninstalled oauthlib-3.3.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: mmh3\n",
            "    Found existing installation: mmh3 5.2.0\n",
            "    Uninstalling mmh3-5.2.0:\n",
            "      Successfully uninstalled mmh3-5.2.0\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: jsonpointer\n",
            "    Found existing installation: jsonpointer 3.0.0\n",
            "    Uninstalling jsonpointer-3.0.0:\n",
            "      Successfully uninstalled jsonpointer-3.0.0\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.12.0\n",
            "    Uninstalling jiter-0.12.0:\n",
            "      Successfully uninstalled jiter-0.12.0\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib_resources 6.5.2\n",
            "    Uninstalling importlib_resources-6.5.2:\n",
            "      Successfully uninstalled importlib_resources-6.5.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: humanfriendly\n",
            "    Found existing installation: humanfriendly 10.0\n",
            "    Uninstalling humanfriendly-10.0:\n",
            "      Successfully uninstalled humanfriendly-10.0\n",
            "  Attempting uninstall: httptools\n",
            "    Found existing installation: httptools 0.7.1\n",
            "    Uninstalling httptools-0.7.1:\n",
            "      Successfully uninstalled httptools-0.7.1\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.2.0\n",
            "    Uninstalling hf-xet-1.2.0:\n",
            "      Successfully uninstalled hf-xet-1.2.0\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.0\n",
            "    Uninstalling filelock-3.20.0:\n",
            "      Successfully uninstalled filelock-3.20.0\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.9.0\n",
            "    Uninstalling distro-1.9.0:\n",
            "      Successfully uninstalled distro-1.9.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.4\n",
            "    Uninstalling charset-normalizer-3.4.4:\n",
            "      Successfully uninstalled charset-normalizer-3.4.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.11.12\n",
            "    Uninstalling certifi-2025.11.12:\n",
            "      Successfully uninstalled certifi-2025.11.12\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 6.2.2\n",
            "    Uninstalling cachetools-6.2.2:\n",
            "      Successfully uninstalled cachetools-6.2.2\n",
            "  Attempting uninstall: bcrypt\n",
            "    Found existing installation: bcrypt 5.0.0\n",
            "    Uninstalling bcrypt-5.0.0:\n",
            "      Successfully uninstalled bcrypt-5.0.0\n",
            "  Attempting uninstall: backoff\n",
            "    Found existing installation: backoff 2.2.1\n",
            "    Uninstalling backoff-2.2.1:\n",
            "      Successfully uninstalled backoff-2.2.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.4.0\n",
            "    Uninstalling attrs-25.4.0:\n",
            "      Successfully uninstalled attrs-25.4.0\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.38.0\n",
            "    Uninstalling uvicorn-0.38.0:\n",
            "      Successfully uninstalled uvicorn-0.38.0\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.2\n",
            "    Uninstalling typing-inspection-0.4.2:\n",
            "      Successfully uninstalled typing-inspection-0.4.2\n",
            "  Attempting uninstall: typer-slim\n",
            "    Found existing installation: typer-slim 0.20.0\n",
            "    Uninstalling typer-slim-0.20.0:\n",
            "      Successfully uninstalled typer-slim-0.20.0\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9.1\n",
            "    Uninstalling rsa-4.9.1:\n",
            "      Successfully uninstalled rsa-4.9.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.37.0\n",
            "    Uninstalling referencing-0.37.0:\n",
            "      Successfully uninstalled referencing-0.37.0\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.2\n",
            "    Uninstalling pyasn1_modules-0.4.2:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "  Attempting uninstall: proto-plus\n",
            "    Found existing installation: proto-plus 1.26.1\n",
            "    Uninstalling proto-plus-1.26.1:\n",
            "      Successfully uninstalled proto-plus-1.26.1\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.38.0\n",
            "    Uninstalling opentelemetry-proto-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.38.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 4.0.0\n",
            "    Uninstalling markdown-it-py-4.0.0:\n",
            "      Successfully uninstalled markdown-it-py-4.0.0\n",
            "  Attempting uninstall: jsonpatch\n",
            "    Found existing installation: jsonpatch 1.33\n",
            "    Uninstalling jsonpatch-1.33:\n",
            "      Successfully uninstalled jsonpatch-1.33\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.76.0\n",
            "    Uninstalling grpcio-1.76.0:\n",
            "      Successfully uninstalled grpcio-1.76.0\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.72.0\n",
            "    Uninstalling googleapis-common-protos-1.72.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.72.0\n",
            "  Attempting uninstall: coloredlogs\n",
            "    Found existing installation: coloredlogs 15.0.1\n",
            "    Uninstalling coloredlogs-15.0.1:\n",
            "      Successfully uninstalled coloredlogs-15.0.1\n",
            "  Attempting uninstall: build\n",
            "    Found existing installation: build 1.3.0\n",
            "    Uninstalling build-1.3.0:\n",
            "      Successfully uninstalled build-1.3.0\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.11.0\n",
            "    Uninstalling anyio-4.11.0:\n",
            "      Successfully uninstalled anyio-4.11.0\n",
            "  Attempting uninstall: watchfiles\n",
            "    Found existing installation: watchfiles 1.1.1\n",
            "    Uninstalling watchfiles-1.1.1:\n",
            "      Successfully uninstalled watchfiles-1.1.1\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.12.0\n",
            "    Uninstalling tiktoken-0.12.0:\n",
            "      Successfully uninstalled tiktoken-0.12.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: requests-toolbelt\n",
            "    Found existing installation: requests-toolbelt 1.0.0\n",
            "    Uninstalling requests-toolbelt-1.0.0:\n",
            "      Successfully uninstalled requests-toolbelt-1.0.0\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 2.0.0\n",
            "    Uninstalling requests-oauthlib-2.0.0:\n",
            "      Successfully uninstalled requests-oauthlib-2.0.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "  Attempting uninstall: posthog\n",
            "    Found existing installation: posthog 5.4.0\n",
            "    Uninstalling posthog-5.4.0:\n",
            "      Successfully uninstalled posthog-5.4.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.38.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.38.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.38.0\n",
            "    Uninstalling opentelemetry-api-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.38.0\n",
            "  Attempting uninstall: onnxruntime\n",
            "    Found existing installation: onnxruntime 1.23.2\n",
            "    Uninstalling onnxruntime-1.23.2:\n",
            "      Successfully uninstalled onnxruntime-1.23.2\n",
            "  Attempting uninstall: jsonschema-specifications\n",
            "    Found existing installation: jsonschema-specifications 2025.9.1\n",
            "    Uninstalling jsonschema-specifications-2025.9.1:\n",
            "      Successfully uninstalled jsonschema-specifications-2025.9.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: grpcio-status\n",
            "    Found existing installation: grpcio-status 1.71.2\n",
            "    Uninstalling grpcio-status-1.71.2:\n",
            "      Successfully uninstalled grpcio-status-1.71.2\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.43.0\n",
            "    Uninstalling google-auth-2.43.0:\n",
            "      Successfully uninstalled google-auth-2.43.0\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.20.0\n",
            "    Uninstalling typer-0.20.0:\n",
            "      Successfully uninstalled typer-0.20.0\n",
            "  Attempting uninstall: replicate\n",
            "    Found existing installation: replicate 1.0.7\n",
            "    Uninstalling replicate-1.0.7:\n",
            "      Successfully uninstalled replicate-1.0.7\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.59b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.59b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.59b0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.8.1\n",
            "    Uninstalling openai-2.8.1:\n",
            "      Successfully uninstalled openai-2.8.1\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.47\n",
            "    Uninstalling langsmith-0.4.47:\n",
            "      Successfully uninstalled langsmith-0.4.47\n",
            "  Attempting uninstall: kubernetes\n",
            "    Found existing installation: kubernetes 34.1.0\n",
            "    Uninstalling kubernetes-34.1.0:\n",
            "      Successfully uninstalled kubernetes-34.1.0\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.25.1\n",
            "    Uninstalling jsonschema-4.25.1:\n",
            "      Successfully uninstalled jsonschema-4.25.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.28.1\n",
            "    Uninstalling google-api-core-2.28.1:\n",
            "      Successfully uninstalled google-api-core-2.28.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.38.0\n",
            "    Uninstalling opentelemetry-sdk-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.38.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.1.0\n",
            "    Uninstalling langchain-core-1.1.0:\n",
            "      Successfully uninstalled langchain-core-1.1.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-grpc\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.38.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.38.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.38.0\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 1.0.0\n",
            "    Uninstalling langchain-text-splitters-1.0.0:\n",
            "      Successfully uninstalled langchain-text-splitters-1.0.0\n",
            "  Attempting uninstall: langchain-openai\n",
            "    Found existing installation: langchain-openai 1.1.0\n",
            "    Uninstalling langchain-openai-1.1.0:\n",
            "      Successfully uninstalled langchain-openai-1.1.0\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.9.0\n",
            "    Uninstalling google-ai-generativelanguage-0.9.0:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.9.0\n",
            "  Attempting uninstall: langchain-google-genai\n",
            "    Found existing installation: langchain-google-genai 3.2.0\n",
            "    Uninstalling langchain-google-genai-3.2.0:\n",
            "      Successfully uninstalled langchain-google-genai-3.2.0\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 1.3.5\n",
            "    Uninstalling chromadb-1.3.5:\n",
            "      Successfully uninstalled chromadb-1.3.5\n",
            "  Attempting uninstall: langchain-chroma\n",
            "    Found existing installation: langchain-chroma 1.0.0\n",
            "    Uninstalling langchain-chroma-1.0.0:\n",
            "      Successfully uninstalled langchain-chroma-1.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "transformers 4.57.2 requires huggingface-hub<1.0,>=0.34.0, but you have huggingface-hub 1.1.5 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.10.0 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "gradio 5.50.0 requires pydantic<=2.12.3,>=2.0, but you have pydantic 2.12.5 which is incompatible.\n",
            "bigframes 2.29.1 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed annotated-types-0.7.0 anyio-4.11.0 attrs-25.4.0 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 cachetools-6.2.2 certifi-2025.11.12 charset_normalizer-3.4.4 chromadb-1.3.5 click-8.3.1 coloredlogs-15.0.1 distro-1.9.0 durationpy-0.10 filelock-3.20.0 filetype-1.2.0 flatbuffers-25.9.23 fsspec-2025.10.0 google-ai-generativelanguage-0.9.0 google-api-core-2.28.1 google-auth-2.43.0 googleapis-common-protos-1.72.0 grpcio-1.76.0 grpcio-status-1.76.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httptools-0.7.1 httpx-0.28.1 huggingface-hub-1.1.5 humanfriendly-10.0 idna-3.11 importlib-metadata-8.7.0 importlib-resources-6.5.2 jiter-0.12.0 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kubernetes-34.1.0 langchain-chroma-1.0.0 langchain-core-1.1.0 langchain-google-genai-3.2.0 langchain-openai-1.1.0 langchain-text-splitters-1.0.0 langsmith-0.4.49 markdown-it-py-4.0.0 mdurl-0.1.2 mmh3-5.2.0 mpmath-1.3.0 numpy-2.3.5 oauthlib-3.3.1 onnxruntime-1.23.2 openai-2.8.1 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 orjson-3.11.4 overrides-7.7.0 packaging-25.0 posthog-5.4.0 proto-plus-1.26.1 protobuf-6.33.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.2 pydantic-2.12.5 pydantic-core-2.41.5 pygments-2.19.2 pymupdf-1.26.6 pypika-0.48.9 pyproject_hooks-1.2.0 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 pyyaml-6.0.3 referencing-0.37.0 regex-2025.11.3 replicate-1.0.7 requests-2.32.5 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-14.2.0 rpds-py-0.29.0 rsa-4.9.1 shellingham-1.5.4 six-1.17.0 sniffio-1.3.1 sympy-1.14.0 tenacity-9.1.2 tiktoken-0.12.0 tokenizers-0.22.1 tqdm-4.67.1 typer-0.20.0 typer-slim-0.20.0 typing-inspection-0.4.2 typing_extensions-4.15.0 urllib3-2.3.0 uvicorn-0.38.0 uvloop-0.22.1 watchfiles-1.1.1 websocket-client-1.9.0 websockets-15.0.1 zipp-3.23.0 zstandard-0.25.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "annotated_types",
                  "attr",
                  "attrs",
                  "bcrypt",
                  "cachetools",
                  "certifi",
                  "chromadb",
                  "click",
                  "dateutil",
                  "dotenv",
                  "filelock",
                  "filetype",
                  "flatbuffers",
                  "fsspec",
                  "google",
                  "grpc",
                  "grpc_status",
                  "httpx",
                  "idna",
                  "importlib_metadata",
                  "jsonpatch",
                  "jsonpointer",
                  "jsonschema",
                  "jsonschema_specifications",
                  "langchain_chroma",
                  "langchain_core",
                  "langchain_google_genai",
                  "langchain_text_splitters",
                  "langsmith",
                  "mpmath",
                  "numpy",
                  "opentelemetry",
                  "orjson",
                  "overrides",
                  "packaging",
                  "proto",
                  "pyasn1",
                  "pybase64",
                  "pydantic",
                  "referencing",
                  "regex",
                  "replicate",
                  "requests",
                  "requests_toolbelt",
                  "rich",
                  "rpds",
                  "rsa",
                  "shellingham",
                  "six",
                  "sympy",
                  "tenacity",
                  "tiktoken",
                  "tiktoken_ext",
                  "tokenizers",
                  "tqdm",
                  "typer",
                  "typing_extensions",
                  "typing_inspection",
                  "urllib3",
                  "zipp",
                  "zstandard"
                ]
              },
              "id": "3466f9b9e81c4b8c9c19f09c1a108f9a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Llama(LLM):\n",
        "    model: str = \"meta/meta-llama-3.1-405b-instruct\"\n",
        "    max_tokens: int = 1024\n",
        "    temperature: float = 0.7\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"replicate_llama\"\n",
        "\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        input_data = {\n",
        "            \"prompt\": prompt,\n",
        "            \"max_tokens\": self.max_tokens,\n",
        "            \"temperature\": self.temperature\n",
        "        }\n",
        "\n",
        "        output = \"\"\n",
        "        for event in replicate.stream(self.model, input=input_data):\n",
        "            output += str(event)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "Cg8st-4R_RN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OCRPDFLoader:\n",
        "    def __init__(self, file_path: str, use_ocr: bool = False, text_threshold: int = 50):\n",
        "        self.file_path = file_path\n",
        "        self.use_ocr = use_ocr\n",
        "        self.text_threshold = text_threshold\n",
        "\n",
        "    def load(self) -> List[Document]:\n",
        "        doc = fitz.open(self.file_path)\n",
        "        documents = []\n",
        "\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc[page_num]\n",
        "            text = page.get_text()\n",
        "\n",
        "            if self.use_ocr or len(text.strip()) < self.text_threshold:\n",
        "                print(f\"OCR: page {page_num + 1}\")\n",
        "                text = self._ocr_page(page, page_num)\n",
        "\n",
        "            if text.strip():\n",
        "                documents.append(Document(\n",
        "                    page_content=text.strip(),\n",
        "                    metadata={\n",
        "                        'source': self.file_path,\n",
        "                        'page': page_num + 1,\n",
        "                        'filename': Path(self.file_path).name\n",
        "                    }\n",
        "                ))\n",
        "\n",
        "        doc.close()\n",
        "        return documents\n",
        "\n",
        "    def _ocr_page(self, page, page_num, temp_dir='./temp_ocr'):\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))\n",
        "        img_path = f\"{temp_dir}/page_{page_num}.png\"\n",
        "        pix.save(img_path)\n",
        "\n",
        "        with open(img_path, \"rb\") as image_file:\n",
        "            input_data = {\n",
        "                \"image\": image_file,\n",
        "                \"task_type\": \"Free OCR\"\n",
        "            }\n",
        "\n",
        "            output = replicate.run(\n",
        "                \"lucataco/deepseek-ocr:cb3b474fbfc56b1664c8c7841550bccecbe7b74c30e45ce938ffca1180b4dff5\",\n",
        "                input=input_data\n",
        "            )\n",
        "\n",
        "        os.remove(img_path)\n",
        "        return output"
      ],
      "metadata": {
        "id": "h7EEIiJTD4T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LangChainPDFRAG:\n",
        "    def __init__(self,\n",
        "                 llm_model=\"meta/meta-llama-3.1-405b-instruct\",\n",
        "                 embedding_model=\"models/embedding-001\",\n",
        "                 persist_directory=\"./chroma_db\"):\n",
        "\n",
        "        self.llm = Llama(model=llm_model)\n",
        "        self.embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model)\n",
        "        self.persist_directory = persist_directory\n",
        "        self.vectorstore = None\n",
        "\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=500,\n",
        "            chunk_overlap=50,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        "        )\n",
        "\n",
        "        if os.path.exists(persist_directory):\n",
        "            self.vectorstore = Chroma(\n",
        "                persist_directory=persist_directory,\n",
        "                embedding_function=self.embeddings\n",
        "            )\n",
        "\n",
        "    def add_pdf(self, pdf_path: str, use_ocr: bool = False):\n",
        "        loader = OCRPDFLoader(pdf_path, use_ocr=use_ocr)\n",
        "        documents = loader.load()\n",
        "\n",
        "        splits = self.text_splitter.split_documents(documents)\n",
        "\n",
        "        if self.vectorstore is None:\n",
        "            self.vectorstore = Chroma.from_documents(\n",
        "                documents=splits,\n",
        "                embedding=self.embeddings,\n",
        "                persist_directory=self.persist_directory\n",
        "            )\n",
        "        else:\n",
        "            self.vectorstore.add_documents(splits)\n",
        "\n",
        "        print(f\"Added {len(splits)} chunks from {Path(pdf_path).name}\")\n",
        "        return len(splits)\n",
        "\n",
        "    def query(self, question: str):\n",
        "        if self.vectorstore is None:\n",
        "            raise ValueError(\"No documents.\")\n",
        "\n",
        "        retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "        def format_docs(docs):\n",
        "            return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(\n",
        "            \"You are a helpful assistant. Answer based on the context provided. Cite page numbers when relevant.\\n\\n\"\n",
        "            \"Context:\\n{context}\\n\\n\"\n",
        "            \"Question: {question}\\n\\n\"\n",
        "            \"Answer:\"\n",
        "        )\n",
        "\n",
        "        chain = (\n",
        "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "            | prompt\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "\n",
        "        docs = retriever.invoke(question)\n",
        "        answer = chain.invoke(question)\n",
        "\n",
        "        return {\n",
        "            'answer': answer,\n",
        "            'sources': [\n",
        "                {\n",
        "                    'filename': doc.metadata.get('filename'),\n",
        "                    'page': doc.metadata.get('page'),\n",
        "                    'content': doc.page_content[:200]\n",
        "                }\n",
        "                for doc in docs\n",
        "            ]\n",
        "        }"
      ],
      "metadata": {
        "id": "okRESTXzFqVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Using Llama 3.1 405B from Replicate\n",
        "    rag = LangChainPDFRAG(llm_model=\"meta/meta-llama-3.1-405b-instruct\")\n",
        "\n",
        "    rag.add_pdf(\"/content/temp.pdf\", use_ocr=True)\n",
        "\n",
        "    result = rag.query(\"What are the main findings?\")\n",
        "\n",
        "    print(\"=== Answer ===\")\n",
        "    print(result['answer'])\n",
        "\n",
        "    print(\"\\n=== Sources ===\")\n",
        "    for source in result['sources']:\n",
        "        print(f\"- {source['filename']}, Page {source['page']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "collapsed": true,
        "id": "jJdESLifJG_Q",
        "outputId": "4d02bccb-60d2-4b1a-b7f6-ad8649a385a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR: page 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ReplicateError",
          "evalue": "ReplicateError Details:\ntitle: Insufficient credit\nstatus: 402\ndetail: You have insufficient credit to run this model. Go to https://replicate.com/account/billing#billing to purchase credit. Once you purchase credit, please wait a few minutes before trying again.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReplicateError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1339618748.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLangChainPDFRAG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"meta/meta-llama-3.1-405b-instruct\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/temp.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_ocr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What are the main findings?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3116261684.py\u001b[0m in \u001b[0;36madd_pdf\u001b[0;34m(self, pdf_path, use_ocr)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_ocr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOCRPDFLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_ocr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_ocr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2190752156.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_ocr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_threshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"OCR: page {page_num + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ocr_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2190752156.py\u001b[0m in \u001b[0;36m_ocr_page\u001b[0;34m(self, page, page_num, temp_dir)\u001b[0m\n\u001b[1;32m     43\u001b[0m             }\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             output = replicate.run(\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0;34m\"lucataco/deepseek-ocr:cb3b474fbfc56b1664c8c7841550bccecbe7b74c30e45ce938ffca1180b4dff5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/replicate/client.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, ref, input, use_file_output, **params)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \"\"\"\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_file_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_file_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     async def async_run(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/replicate/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(client, ref, input, use_file_output, **params)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         prediction = client.predictions.create(\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/replicate/prediction.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, version, deployment, input, *args, **params)\u001b[0m\n\u001b[1;32m    495\u001b[0m         )\n\u001b[1;32m    496\u001b[0m         \u001b[0mextras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_prediction_request_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/v1/predictions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_json_to_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/replicate/client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, path, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/replicate/client.py\u001b[0m in \u001b[0;36m_raise_for_status\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mReplicateError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mReplicateError\u001b[0m: ReplicateError Details:\ntitle: Insufficient credit\nstatus: 402\ndetail: You have insufficient credit to run this model. Go to https://replicate.com/account/billing#billing to purchase credit. Once you purchase credit, please wait a few minutes before trying again."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cadf4967",
        "outputId": "d30cc049-368f-4d37-a576-b63369fb6ac0"
      },
      "source": [
        "!pip install replicate\n",
        "import os\n",
        "import replicate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.language_models.llms import LLM\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from typing import List, Optional, Any\n",
        "import fitz\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: replicate in /usr/local/lib/python3.12/dist-packages (1.0.7)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from replicate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from replicate) (25.0)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.12/dist-packages (from replicate) (2.12.5)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from replicate) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.21.0->replicate) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>1.10.7->replicate) (0.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "auto-generated-id-1",
        "outputId": "81f702b4-316f-4976-c64d-55271c4bd851"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set your Gemini API Key\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# Set your Replicate API Token\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = userdata.get('REPLICATE_API_TOKEN')\n",
        "\n",
        "print(\"API keys set successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API keys set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eadaee1f"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ba58968",
        "outputId": "528d7bf0-d571-4d36-9cd9-8c2060a430e0"
      },
      "source": [
        "import os\n",
        "import replicate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.language_models.llms import LLM\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from typing import List, Optional, Any\n",
        "import fitz\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}